{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinal Organoid Calcium Imaging Pipeline\n",
    "\n",
    "This notebook demonstrates the full analysis pipeline for calcium imaging data from retinal organoids.\n",
    "\n",
    "## Pipeline overview\n",
    "1. Load OME-TIFF and extract sampling rate\n",
    "2. Compute variance and activity maps\n",
    "3. Segment ROIs via watershed on the activity score map\n",
    "4. Build neuropil annuli and extract traces\n",
    "5. Compute ΔF/F₀ with neuropil subtraction\n",
    "6. Extract peak features (ISI, prominence, width)\n",
    "7. Compute pairwise cross-correlation and lag matrices\n",
    "8. Build functional + spatial affinity and cluster ROIs\n",
    "9. Compute magnitude-squared coherence and CSD features\n",
    "10. Save all outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi\n",
    "from tifffile import TiffFile\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from pipeline import (\n",
    "    get_sampling_rate_hz, activity_image_stream, dog2d,\n",
    "    segment_rois_from_score2d, make_neuropil_masks, extract_traces,\n",
    "    dff_from_traces, make_temporal_kernel, matched_filter_traces,\n",
    "    compute_xcorr_lag_matrix, functional_affinity, spatial_affinity,\n",
    "    combined_affinity, hclust_auto_clusters_from_affinity,\n",
    "    extract_peak_features, compute_coherence_features, save_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifpath = r'path/to/your/recording.ome.tif'\n",
    "\n",
    "with TiffFile(tifpath) as tif:\n",
    "    video = tif.series[0].asarray()\n",
    "\n",
    "fs = get_sampling_rate_hz(tifpath)\n",
    "print(f'Video shape: {video.shape}, Sampling rate: {fs:.2f} Hz')\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(video[0], cmap='gray')\n",
    "plt.title('First frame')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute variance and activity score maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_varframe = np.zeros_like(video[0], dtype=np.float32)\n",
    "window_size = (100, 100)\n",
    "slide_step = 100\n",
    "for y in range(0, video.shape[1] - window_size[0] + 1, slide_step):\n",
    "    y_a = min(y, video.shape[1] - window_size[0])\n",
    "    y_b = y_a + window_size[0]\n",
    "    for x in range(0, video.shape[2], slide_step):\n",
    "        x_a = min(x, video.shape[2] - window_size[1])\n",
    "        x_b = x_a + window_size[1]\n",
    "        total_varframe[y_a:y_b, x_a:x_b] = np.var(video[:2500, y_a:y_b, x_a:x_b], axis=0)\n",
    "\n",
    "S = activity_image_stream(video, fs, hp_s=2.0, chunk_T=512)\n",
    "S_f = dog2d(S, sigma_small=1.0, sigma_large=4.0)\n",
    "med = np.median(S_f)\n",
    "mad = np.median(np.abs(S_f - med)) + 1e-6\n",
    "score2d = (S_f - med) / mad\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "axes[0].imshow(total_varframe, cmap='gray')\n",
    "axes[0].set_title('Variance image')\n",
    "axes[1].imshow(score2d, cmap='gray')\n",
    "axes[1].set_title('Activity score (z-scored DoG)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segment ROIs and build neuropil masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_labels = segment_rois_from_score2d(score2d)\n",
    "neuropil_labels = make_neuropil_masks(roi_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(roi_labels, cmap='nipy_spectral')\n",
    "plt.imshow(neuropil_labels, cmap='nipy_spectral', alpha=0.2)\n",
    "plt.title(f'{roi_labels.max()} ROIs detected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract traces and compute ΔF/F₀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_ids, F_corr, F_roi, F_np = extract_traces(video, roi_labels, neuropil_labels, neuropil_scale=0.7)\n",
    "\n",
    "dff, F0, Fcorr = dff_from_traces(F_roi, F_np, fs=fs,\n",
    "                                  neuropil_scale=0.7,\n",
    "                                  baseline_win_s=60,\n",
    "                                  baseline_percentile=10,\n",
    "                                  f0_floor=1.0)\n",
    "\n",
    "k_t = make_temporal_kernel(fs)\n",
    "spike_score = matched_filter_traces(F_corr, k_t)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "offset = 0\n",
    "for i in range(min(10, dff.shape[0])):\n",
    "    plt.plot(np.arange(dff.shape[1]) / fs, dff[i] + offset, linewidth=0.5)\n",
    "    offset += np.nanmax(dff[i]) * 1.1\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('ΔF/F₀ (stacked)')\n",
    "plt.title('Example ΔF/F₀ traces')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Peak detection and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_np, parameters, peak_indexes = extract_peak_features(dff, prominence_thresh=0.1)\n",
    "print(f'Features extracted for {dff.shape[0]} ROIs')\n",
    "print('Parameters:', parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-correlation, affinity, and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, M, C = compute_xcorr_lag_matrix(dff, max_lag=500)\n",
    "\n",
    "masks = np.array([roi_labels == rid for rid in roi_ids])\n",
    "centers = np.array([ndi.center_of_mass(m.astype(float)) for m in masks])\n",
    "D = cdist(centers, centers)\n",
    "\n",
    "Wt = functional_affinity(L, M, tau_lag=50)\n",
    "Ws, sigma_pix = spatial_affinity(D)\n",
    "W = combined_affinity(Wt, Ws, lam=0.7, beta=0.5)\n",
    "labels, Z, t = hclust_auto_clusters_from_affinity(W, method='complete')\n",
    "\n",
    "print(f'{len(np.unique(labels))} clusters found')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axes[0].imshow(C, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[0].set_title('Pearson correlation')\n",
    "axes[1].imshow(L, cmap='coolwarm')\n",
    "axes[1].set_title('Lag at max cross-correlation (frames)')\n",
    "axes[2].imshow(W, cmap='viridis')\n",
    "axes[2].set_title('Combined affinity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Coherence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nperseg = min(512, video.shape[0])\n",
    "noverlap = nperseg // 2\n",
    "score_per_trace, C_band, S_band, GC_band = compute_coherence_features(\n",
    "    dff, fs=1.0, nperseg=nperseg, noverlap=noverlap\n",
    ")\n",
    "\n",
    "print(f'Global coherence (band-averaged): {GC_band:.4f}')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].bar(range(len(score_per_trace)), score_per_trace)\n",
    "axes[0].set_xlabel('ROI')\n",
    "axes[0].set_ylabel('Weighted coherence with mean')\n",
    "axes[0].set_title('Per-ROI coherence score')\n",
    "axes[1].imshow(C_band, cmap='viridis')\n",
    "axes[1].set_title('Band-averaged coherence matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = save_results(\n",
    "    tifpath, video, total_varframe, score2d,\n",
    "    roi_labels, neuropil_labels,\n",
    "    F_roi, F_np, F_corr, dff, labels,\n",
    "    peak_indexes, parameters_np, parameters,\n",
    "    C, L, M, D, W,\n",
    "    score_per_trace, C_band, S_band\n",
    ")\n",
    "print(f'Results saved to: {out_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
